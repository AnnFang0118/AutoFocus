import { useEffect, useRef, useState } from "react";

const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);

const AutoCamera = () => {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const [devices, setDevices] = useState([]);
  const [stream, setStream] = useState(null);
  const [imageCapture, setImageCapture] = useState(null);
  const [currentDeviceId, setCurrentDeviceId] = useState(null);
  const [error, setError] = useState("");
  const [loading, setLoading] = useState(false);

  const isVirtual = (label) => /virtual|snap|obs|filter/i.test(label);
  const isFrontCamera = (label) => /front|facetime|self|å‰/i.test(label);

  const stopStream = () => {
    if (stream) {
      stream.getTracks().forEach((t) => t.stop());
      setStream(null);
    }
    setImageCapture(null);
  };

  const getDevices = async () => {
    try {
      await navigator.mediaDevices.getUserMedia({ video: true }); // unlock labels
      const all = await navigator.mediaDevices.enumerateDevices();
      const filtered = all.filter(
        (d) =>
          d.kind === "videoinput" &&
          !isVirtual(d.label || "") &&
          !isFrontCamera(d.label || "")
      );
      return filtered;
    } catch (err) {
      setError("ğŸš« ç„¡æ³•å–å¾—ç›¸æ©Ÿæ¸…å–®ï¼Œè«‹ç¢ºèªæ¬Šé™");
      return [];
    }
  };

  const detectAutoFocus = async (list) => {
    const results = [];

    for (const d of list) {
      try {
        const testStream = await navigator.mediaDevices.getUserMedia({
          video: { deviceId: { exact: d.deviceId } },
        });
        const track = testStream.getVideoTracks()[0];
        const caps = track.getCapabilities?.();
        const hasAF =
          caps?.focusMode?.includes("continuous") ||
          caps?.focusMode?.includes("auto");
        track.stop();
        if (hasAF) results.push(d);
      } catch (_) {}
    }

    return results;
  };

  const startCamera = async (deviceId = null) => {
    if (loading) return;
    setLoading(true);
    setError("");

    try {
      stopStream();
      await new Promise((r) => setTimeout(r, 200));

      const constraints = isIOS
        ? { video: { facingMode: { exact: "environment" } } }
        : { video: { deviceId: { exact: deviceId } } };

      let mediaStream;

      try {
        mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
      } catch (err) {
        // fallback: è‹¥ deviceId ç„¡æ•ˆå‰‡æ”¹ç”¨ facingMode
        console.warn("ä½¿ç”¨ deviceId å•Ÿå‹•å¤±æ•—ï¼Œå˜—è©¦ fallback:", err);
        mediaStream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { exact: "environment" } },
        });
      }

      setStream(mediaStream);
      setCurrentDeviceId(deviceId);

      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
      }

      const track = mediaStream.getVideoTracks()[0];
      if (!isIOS && "ImageCapture" in window) {
        try {
          const capture = new ImageCapture(track);
          setImageCapture(capture);
        } catch (err) {
          console.warn("ImageCapture å»ºç«‹å¤±æ•—ï¼š", err);
        }
      }
    } catch (err) {
      console.error("å•Ÿç”¨ç›¸æ©Ÿå¤±æ•—ï¼š", err);
      setError("ğŸš« ç„¡æ³•å•Ÿç”¨ç›¸æ©Ÿï¼Œè«‹æª¢æŸ¥æ¬Šé™èˆ‡ç€è¦½å™¨ç›¸å®¹æ€§");
    } finally {
      setLoading(false);
    }
  };

  const takePhoto = async () => {
    if (!canvasRef.current || !videoRef.current) return;

    const canvas = canvasRef.current;
    const video = videoRef.current;
    const ctx = canvas.getContext("2d");

    if (!isIOS && imageCapture) {
      try {
        const blob = await imageCapture.takePhoto();
        const bitmap = await createImageBitmap(blob);
        canvas.width = bitmap.width;
        canvas.height = bitmap.height;
        ctx.drawImage(bitmap, 0, 0);
        return;
      } catch (err) {
        console.warn("ImageCapture æ‹ç…§å¤±æ•—ï¼Œä½¿ç”¨æˆªåœ–æ–¹å¼", err);
      }
    }

    // fallbackï¼šç•«é¢æˆªåœ–æ–¹å¼
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  };

  useEffect(() => {
    (async () => {
      const allDevices = await getDevices();
      let chosen = null;

      if (isIOS) {
        chosen = allDevices[0];
        await startCamera(); // iOS æ”¹ç”¨ facingMode
      } else {
        const withAF = await detectAutoFocus(allDevices);
        chosen = withAF[0] || allDevices[0];
        if (chosen) await startCamera(chosen.deviceId);
      }

      setDevices(allDevices);
    })();

    return stopStream;
  }, []);

  return (
    <div style={{ fontFamily: "sans-serif", padding: "20px" }}>
      <h2>ğŸ“· è‡ªå‹•å°ç„¦ç›¸æ©Ÿ</h2>
      {error && <p style={{ color: "red" }}>{error}</p>}

      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        style={{
          width: "100%",
          maxWidth: "500px",
          border: "1px solid #ccc",
          borderRadius: "8px",
        }}
      />

      <button onClick={takePhoto} style={{ marginTop: "10px" }}>
        ğŸ“¸ æ‹ç…§
      </button>

      <canvas
        ref={canvasRef}
        style={{
          width: "100%",
          maxWidth: "500px",
          marginTop: "10px",
          border: "1px solid #aaa",
        }}
      />

      <h3>ğŸ›ï¸ å¯ç”¨å¾Œé¡é ­</h3>
      <ul>
        {devices.map((d) => (
          <li key={d.deviceId}>
            {d.label || "Camera"}
            {currentDeviceId === d.deviceId && (
              <strong style={{ color: "green" }}> â† ä½¿ç”¨ä¸­</strong>
            )}
            {!isIOS && (
              <div>
                <button onClick={() => startCamera(d.deviceId)} disabled={loading}>
                  åˆ‡æ›
                </button>
              </div>
            )}
          </li>
        ))}
      </ul>
    </div>
  );
};

export default AutoCamera;


